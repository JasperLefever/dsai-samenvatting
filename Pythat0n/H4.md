# H4 -> 2 kwalitatieve variabelen

## Contingency tables and visualisation techniques

```py
# Contingency table -> oppassen met de margins -> als je de margins erbij zet dan krijg je een extra kolom en rij met de totalen -> dit is niet goed voor de chi-quadraat test
pd.crosstab(data.x, data.y, margins=True, margins_name="Total")
# Contingency table -> zonder de margins
pd.crosstab(data.x, data.y)
```

### Clustered bar chart

```py
# Clustered bar chart
# hue is de opsplitsing van de data
sns.catplot(x="x", hue="y", data=data, kind="count")
```

### Stacked bar chart

```py
# Contingency table without the margins
observed = pd.crosstab(rlanders.Gender, rlanders.Survey, normalize='index')

# Horizontally oriented stacked bar chart
observed.plot(kind='barh', stacked=True)


# andere optie
observed.T.plot(kind='bar', stacked=True)
```

## Chi-squared and Cramér's V

### Chi-squared test

1. Formulate the hypotheses:
   - $H_0$: There is no association between the variables (the differences between observed and expected values are small)
   - $H_1$: There is an association between the variables (the differences are large)
2. Choose significance level $\alpha$
3. Calculate the value of the test statistic in the sample (here: $\chi^2$).
4. Use one of the following methods (based on the degrees of freedom $df = (r-1) \times (k-1)$):
   1. Determine critical value $g$ so $P(\chi^2 > g) = \alpha$
   2. Calculate the $p$-value
5. Draw a conclusion based on the outcome:
   1. $\chi^2 < g$: do not reject $H_0$; $\chi^2 > g$: reject $H_0$
   2. $p > \alpha$: do not reject $H_0$; $p < \alpha$: reject $H_0$

```py
'''
Step 1: State the hypotheses
H0: Er is geen verband tussen rookgedrag en lichaamsbeweging
H1: Er is wel een verband tussen rookgedrag en lichaamsbeweging

Step 2: Choose significance level
α = 0.05

Step 3: Calculate the chi-square statistic
chi2=5.489

Step4 calculate the critical value (g)
g= 12.5916

step 5: the p-value
p=0.4828

Step 6: Consliusion
There is not enough evidence to reject the null hypothesis. (chi2 < g and p > α)

'''
```

```py
observed = pd.crosstab(rlanders.Survey, rlanders.Gender)
chi2, p, df, expected = stats.chi2_contingency(observed)
alpha = .05

print("Chi-squared : %.4f" % chi2)
print("Degrees of freedom: %d" % df)
print("P-value : %.4f" % p)

g = stats.chi2.isf(alpha, df = df)
print("Critical value     : %.4f" % g)
```

```py
alpha = .05
dimensions = observed.shape
dof = (dimensions[0]-1) * (dimensions[1]-1)

print("Chi-squared        : %.4f" % chi_squared)
print("Degrees of freedom : %d" % dof)

# Calculate critical value
g = stats.chi2.isf(alpha, df = dof)
print("Critical value     : %.4f" % g)

# Calculate p-value
p = stats.chi2.sf(chi_squared, df=dof)
print("p-value            : %.4f" % p)
```

### Cramér's V

- is a formula that normalises $\chi^2$ to a value between 0 and 1 that is independent of the table size.

| Cramér's V | Interpretation          |
| :--------: | :---------------------- |
|     0      | No association          |
|    0.1     | Weak association        |
|    0.25    | Moderate association    |
|    0.50    | Strong association      |
|    0.75    | Very strong association |
|     1      | Complete association    |

```py
# Cramér's V
dof = min(observed.shape) - 1
cramers_v = np.sqrt(chi_squared / (dof * n))
print(cramers_v)
```

## Goodness of fit test

- controleren of sample representatief is voor de populatie

1. Formulate the hypotheses:
   - $H_0$: The sample is representative of the population, i.e. the frequency of each class within the sample corresponds well to that in the population.
   - $H_1$: The sample is _not_ representative of the population, i.e. the differences with the expected frequencies are too large.
2. Choose significance level $\alpha$
3. Calculate the value of the test statistic in the sample (here: $\chi^2$).
4. Use one of the following methods (based on the degrees of freedom $df = (k-1)$ with $k$ the number of categories in the sample):
   1. Determine critical value $g$ so $P(\chi^2 > g) = \alpha$
   2. Calculate the $p$-value
5. Draw a conclusion based on the outcome:
   1. $\chi^2 < g$: do not reject $H_0$; $\chi^2 > g$: reject $H_0$
   2. $p > \alpha$: do not reject $H_0$; $p < \alpha$: reject $H_0$

```py
observed = np.array([127, 75, 98, 27, 73])
expected_p = np.array([.35, .17, .23, .08, .17])
expected = expected_p * sum(observed)
chi2, p = stats.chisquare(f_obs=observed, f_exp=expected)

print(”χ² = %.4f” % chi2)
print(”p = %.4f” % p)
```

## Standardised residuals

- kijken of uw sample overrepresentatief is voor een bepaalde groep of niet
- na chi-squared test

```py
# Standardised residuals -> heb een functie gemaakt ervoor xd
# zorg dat expected_p in de dataframe zit
# zorg dat observed in de dataframe zit
# zorg dat expected in de dataframe zit
def calculate_stdres(contingency_table):
    """
    Calculates the standardized residuals for a contingency table.

    Args:
    contingency_table (pd.DataFrame): A contingency table with observed and expected frequencies.

    Returns:
    pd.DataFrame: The contingency table with added column for standardized residuals.
    """
    # Calculate the standardized residuals
    contingency_table['stdres'] = (contingency_table['observed'] - contingency_table['expected']) / np.sqrt(contingency_table['expected'] * (1 - contingency_table['expected_p']))

    return contingency_table
```

## Cochran's rule

- Chi-quadraat test enkel juiste resultaat als er voldoende data is

  - Contingency table -> 2x2
  - Alle expected values > 1
  - minstens 20% expected values > 5
